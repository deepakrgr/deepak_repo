>>> userDF=spark.read.json("users.json")
>>> userDF.printSchema()
root
|-- children: string (nullable = true)
|-- father: string (nullable = true)
|-- id: long (nullable = true)
|-- mother: string (nullable = true)

>>> userDF.show()
+--------+------+---+---------+
|children|father| id|   mother|
+--------+------+---+---------+
|    null|  Mark|  1|Charlotte|
| Jessika|  John|  2|      Ann|
|   Karol|   Bob|  3|   Monika|
+--------+------+---+---------+
>>> childernDF=userDF.select("mother","id")
>>> childernDF.show()
+---------+---+
|   mother| id|
+---------+---+
|Charlotte|  1|
|      Ann|  2|
|   Monika|  3|
+---------+---+

>>> children_With_id_over_1=childernDF.where("id > 1")
>>> children_With_id_over_1.show()
+------+---+                                                                    
|mother| id|
+------+---+
|   Ann|  2|
|Monika|  3|
+------+---+
>>> chidlchildren_With_id_over_1_1 = userDF.select("mother","id").where("id > 1")

>>> chidlchildren_With_id_over_1_1.show()
+------+---+                                                                    
|mother| id|
+------+---+
|   Ann|  2|
|Monika|  3|
+------+---+



===== Data frame from In memory data =====

SparkSession available as 'spark'.
>>> mydata = [('mathew','19'),('adam','20')]
>>> mydf = spark.createDataFrame(mydata)
>>> mydf.show()
+------+---+                                                                    
|    _1| _2|
+------+---+
|mathew| 19|
|  adam| 20|
+------+---+

>>> mydf.printSchema()
root
 |-- _1: string (nullable = true)
 |-- _2: string (nullable = true)

>>> mydf.write.mode("append").option("path","/user/hrt_qa/abcd")
<pyspark.sql.readwriter.DataFrameWriter object at 0x7f12d4f1a210>
>>> mydf.write.mode("append").option("path","/user/hrt_qa/abcd").saveAsTable("test_spark")
