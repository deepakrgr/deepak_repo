>>> userDF=spark.read.json("users.json")
>>> userDF.printSchema()
root
|-- children: string (nullable = true)
|-- father: string (nullable = true)
|-- id: long (nullable = true)
|-- mother: string (nullable = true)

>>> userDF.show()
+--------+------+---+---------+
|children|father| id|   mother|
+--------+------+---+---------+
|    null|  Mark|  1|Charlotte|
| Jessika|  John|  2|      Ann|
|   Karol|   Bob|  3|   Monika|
+--------+------+---+---------+
>>> childernDF=userDF.select("mother","id")
>>> childernDF.show()
+---------+---+
|   mother| id|
+---------+---+
|Charlotte|  1|
|      Ann|  2|
|   Monika|  3|
+---------+---+

>>> children_With_id_over_1=childernDF.where("id > 1")
>>> children_With_id_over_1.show()
+------+---+                                                                    
|mother| id|
+------+---+
|   Ann|  2|
|Monika|  3|
+------+---+
>>> chidlchildren_With_id_over_1_1 = userDF.select("mother","id").where("id > 1")

>>> chidlchildren_With_id_over_1_1.show()
+------+---+                                                                    
|mother| id|
+------+---+
|   Ann|  2|
|Monika|  3|
+------+---+



===== Data frame from In memory data =====

SparkSession available as 'spark'.
>>> mydata = [('mathew','19'),('adam','20')]
>>> mydf = spark.createDataFrame(mydata)
>>> mydf.show()
+------+---+                                                                    
|    _1| _2|
+------+---+
|mathew| 19|
|  adam| 20|
+------+---+

>>> mydf.printSchema()
root
 |-- _1: string (nullable = true)
 |-- _2: string (nullable = true)
==============



>>> mydf.write.mode("append").option("path","/user/hrt_qa/abcd")
<pyspark.sql.readwriter.DataFrameWriter object at 0x7f12d4f1a210>
>>> mydf.write.mode("append").option("path","/user/hrt_qa/abcd").saveAsTable("test_spark")
>>> mydf.write.mode("append").option("path","/user/hrt_qa/abcde").saveAsTable("test_spark1")
>>> 19/12/03 12:07:49 WARN sql.CommandsHarvester$: Missing unknown leaf node: LogicalRDD [_1#0, _2#1], false


>>> mydf.write.save("test_spark_json")
>>> 19/12/03 12:10:59 WARN sql.CommandsHarvester$: Missing unknown leaf node: LogicalRDD [_1#0, _2#1], false


>>> mydf.write.format("json").save("test_spark_json_1")
>>> 19/12/03 12:12:17 WARN sql.CommandsHarvester$: Missing unknown leaf node: LogicalRDD [_1#0, _2#1], false

Found 3 items
-rw-r--r--   3 hrt_qa supergroup          0 2019-12-03 12:10 /user/hrt_qa/test_spark_json/_SUCCESS
-rw-r--r--   3 hrt_qa supergroup        648 2019-12-03 12:10 /user/hrt_qa/test_spark_json/part-00000-7d8cbea8-9cbf-46c9-b01a-e1592db6172e-c000.snappy.parquet
-rw-r--r--   3 hrt_qa supergroup        634 2019-12-03 12:10 /user/hrt_qa/test_spark_json/part-00001-7d8cbea8-9cbf-46c9-b01a-e1592db6172e-c000.snappy.parquet
Found 3 items
-rw-r--r--   3 hrt_qa supergroup          0 2019-12-03 12:12 /user/hrt_qa/test_spark_json_1/_SUCCESS
-rw-r--r--   3 hrt_qa supergroup         26 2019-12-03 12:12 /user/hrt_qa/test_spark_json_1/part-00000-7d155d22-1ded-43d4-83fd-0a06e6f2f62c-c000.json
-rw-r--r--   3 hrt_qa supergroup         24 2019-12-03 12:12 /user/hrt_qa/test_spark_json_1/part-00001-7d155d22-1ded-43d4-83fd-0a06e6f2f62c-c000.json



>>> mydf.select(mydf._2).show()
+---+                                                                           
| _2|
+---+
| 19|
| 20|
+---+


>>> mydf = spark.read.table("test_spark")
>>> mydf.select(mydf._2*10).show()
+---------+                                                                     
|(_2 * 10)|
+---------+
|    190.0|
|    200.0|
+---------+

>>> mydf.select((mydf._2 * 10).alias('age_10')).show()
+------+
|age_10|
+------+
| 190.0|
| 200.0|
+------+

>>> mydf.groupBy("_2").count().show()
+---+-----+                                                                     
| _2|count|
+---+-----+
| 19|    1|
| 20|    1|
+---+-----+



